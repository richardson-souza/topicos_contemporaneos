{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao PyTorch\n",
    "\n",
    "## O que é PyTorch?\n",
    "PyTorch é uma biblioteca de aprendizado profundo de código aberto desenvolvida pelo Facebook's AI Research lab (FAIR). Ela é amplamente utilizada para tarefas de visão computacional e processamento de linguagem natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### História e contexto\n",
    "PyTorch foi lançado em janeiro de 2017. Ele é baseado na biblioteca Torch, que é uma estrutura de aprendizado de máquina em Lua. PyTorch é conhecido por sua facilidade de uso e integração com Python, o que o torna popular entre pesquisadores e engenheiros.\n",
    "\n",
    "### Comparação com outras bibliotecas\n",
    "- **TensorFlow**: Desenvolvido pelo Google, TensorFlow é uma das bibliotecas de aprendizado profundo mais populares. Enquanto TensorFlow é conhecido por sua escalabilidade e produção, PyTorch é elogiado por sua facilidade de uso e flexibilidade.\n",
    "- **NumPy**: NumPy é uma biblioteca fundamental para computação científica em Python. PyTorch usa tensores, que são similares aos arrays do NumPy, mas com suporte para computação em GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que são tensores?\n",
    "Tensores são a estrutura de dados fundamental em PyTorch. Eles são similares aos arrays do NumPy, mas com suporte para computação em GPU.\n",
    "\n",
    "Tensores 1D, 2D, 3D, etc.\n",
    "- 1D: Vetores\n",
    "- 2D: Matrizes\n",
    "- 3D: Matrizes tridimensionais (cubos de dados)\n",
    "- ND: Tensores de N dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 1D\n",
    "tensor_1d = torch.tensor([1, 2, 3, 4])\n",
    "print(tensor_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 2D\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(tensor_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 3D\n",
    "tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(tensor_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de dados\n",
    "Os tensores em PyTorch suportam vários tipos de dados, como inteiros e floats. O tipo de dado pode ser especificado durante a criação do tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Criação de um tensor de inteiros\n",
    "tensor_int = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "print(tensor_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Criação de um tensor de floats\n",
    "tensor_float = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print(tensor_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propriedade requires_grad\n",
    "A propriedade `requires_grad` em PyTorch é fundamental para a construção e treinamento de redes neurais, pois permite calcular automaticamente os gradientes das operações. Quando `requires_grad` é definido como `True` em um tensor, todas as operações feitas nesse tensor serão rastreadas para a diferenciação automática.\n",
    "\n",
    "### Autograd e Grafos Computacionais\n",
    "\n",
    "Autograd é um componente essencial em frameworks de deep learning como PyTorch, que permite a diferenciação automática de tensores. Este mecanismo é fundamental para a otimização dos modelos de aprendizado de máquina, pois permite calcular gradientes de forma eficiente, necessária para o ajuste dos parâmetros do modelo durante o treinamento.\n",
    "\n",
    "#### Grafos Computacionais\n",
    "\n",
    "Para entender o funcionamento do autograd, é importante compreender os grafos computacionais. Um grafo computacional é uma representação gráfica de uma sequência de operações matemáticas, onde:\n",
    "\n",
    "- **Nós (nodes)** representam operações matemáticas ou variáveis.\n",
    "- **Arestas (edges)** representam os fluxos de dados (tensores) entre as operações.\n",
    "\n",
    "![alt text](https://miro.medium.com/max/908/1*ahiviCqq6B0R_XWBmgvHkA.png \"Grafo Computacional\")\n",
    "\n",
    "Durante a construção de um modelo, as operações realizadas nos tensores criam um grafo computacional dinâmico, também conhecido como *Dynamic Computation Graph*. Esse grafo é dinâmico porque é construído à medida que as operações são executadas, permitindo flexibilidade e facilidade na criação e modificação de modelos.\n",
    "\n",
    "#### Propagação para Frente (Forward Pass)\n",
    "\n",
    "Durante a propagação para frente (forward pass), os tensores são passados através das operações definidas no grafo computacional, produzindo uma saída. Este processo é usado para calcular a perda (loss) do modelo.\n",
    "\n",
    "#### Propagação para Trás (Backward Pass)\n",
    "\n",
    "A propagação para trás (backward pass) é o processo de calcular os gradientes dos tensores em relação à perda, utilizando a regra da cadeia. O autograd facilita essa tarefa, realizando automaticamente a diferenciação reversa ao longo do grafo computacional. Os passos são:\n",
    "\n",
    "1. **Calcula a perda**: A partir das saídas do forward pass.\n",
    "2. **Calcula os gradientes**: Utilizando a diferenciação automática.\n",
    "3. **Atualiza os parâmetros**: Os gradientes calculados são usados para ajustar os parâmetros do modelo através de otimização, como o gradiente descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando Tensores com `requires_grad`\n",
    "\n",
    "Vamos criar tensores com a propriedade `requires_grad` definida como `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor com requires_grad\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando Operações com Tensores que Têm `requires_grad`\n",
    "\n",
    "Quando realizamos operações com tensores que têm `requires_grad=True`, o PyTorch cria uma tape (fita) para rastrear todas as operações. Vamos ver um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Realiza uma operação com o tensor x\n",
    "y = x ** 2\n",
    "\n",
    "# Mais uma operação\n",
    "z = y.sum()\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando Gradientes\n",
    "\n",
    "Para calcular os gradientes, usamos o método `backward()`. Isso calcula o gradiente da função de perda em relação a todos os tensores que têm `requires_grad=True`.\n",
    "\n",
    "Os gradientes armazenados em `x.grad` representam a derivada da soma `z` em relação a `x`. Como `z` é a soma dos elementos de `y` e `y = x ** 2`, a derivada de `z` em relação a `x` é `2 * x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "# Calcula os gradientes\n",
    "z.backward()\n",
    "\n",
    "# Imprime os gradientes armazenados em x.grad\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desativando o Rastreamento de Gradientes\n",
    "\n",
    "Em algumas situações, não queremos rastrear as operações, como durante a inferência do modelo. Podemos desativar temporariamente o rastreamento de gradientes usando `torch.no_grad()` ou `detach()`. Vamos ver como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Desativando o rastreamento de gradientes temporariamente\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "    print(y.requires_grad)  # False, pois o rastreamento está desativado\n",
    "\n",
    "# Criando um novo tensor sem rastreamento de gradientes\n",
    "x_detached = x.detach()\n",
    "print(x_detached.requires_grad)  # False, pois o tensor foi separado da tape de computação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando se um Tensor Requer Gradiente\n",
    "\n",
    "Podemos verificar se um tensor requer gradiente usando a propriedade `requires_grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)  # True, pois x foi criado com requires_grad=True\n",
    "print(x_detached.requires_grad)  # False, pois x_detached foi separado da tape de computação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Criação de Tensores\n",
    "PyTorch fornece várias funções utilitárias para criar tensores de forma eficiente.\n",
    "\n",
    "- `torch.zeros`: Cria um tensor preenchido com zeros.\n",
    "- `torch.zeros_like`: Cria um tensor preenchido com zeros, com as mesmas dimensões de um tensor dado.\n",
    "- `torch.ones`: Cria um tensor preenchido com uns.\n",
    "- `torch.ones_like`: Cria um tensor preenchido com uns, com as mesmas dimensões de um tensor dado.\n",
    "- `torch.linspace`: Cria um tensor com valores linearmente espaçados entre dois pontos.\n",
    "- `torch.arange`: Cria um tensor com valores em uma faixa específica com um passo definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Criação de tensores de zeros\n",
    "tensor_zeros = torch.zeros(3, 3)\n",
    "print(tensor_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Criação de tensores de zeros_like\n",
    "tensor_zeros_like = torch.zeros_like(tensor_2d)\n",
    "print(tensor_zeros_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Criação de tensores de uns\n",
    "tensor_ones = torch.ones(2, 2)\n",
    "print(tensor_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Criação de tensores de ones_like\n",
    "tensor_ones_like = torch.ones_like(tensor_2d)\n",
    "print(tensor_ones_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "# Linspace\n",
    "tensor_linspace = torch.linspace(0, 10, steps=5)\n",
    "print(tensor_linspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# Arange\n",
    "tensor_arange = torch.arange(0, 10, step=2)\n",
    "print(tensor_arange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexação e Fatiamento\n",
    "A indexação e o fatiamento em PyTorch são similares ao NumPy, permitindo acessar e modificar partes específicas de um tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([2, 5, 8])\n",
      "tensor([[5, 6],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor exemplo\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Indexação\n",
    "print(tensor[0, :])  # Primeira linha\n",
    "print(tensor[:, 1])  # Segunda coluna\n",
    "\n",
    "# Fatiamento\n",
    "print(tensor[1:, 1:])  # Subtensor a partir da segunda linha e segunda coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações básicas com tensores\n",
    "PyTorch suporta várias operações básicas com tensores, como adição, multiplicação, subtração e divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ tensor([5, 7, 9])\n",
      "* tensor([ 4, 10, 18])\n",
      "- tensor([-3, -3, -3])\n",
      "/ tensor([0.2500, 0.4000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Adição\n",
    "print(\"+\", a + b)\n",
    "\n",
    "# Multiplicação\n",
    "print(\"*\", a * b)\n",
    "\n",
    "# Subtração\n",
    "print(\"-\", a - b)\n",
    "\n",
    "# Divisão\n",
    "print(\"/\", a / b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando formato (shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(12).reshape(4, 3)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View\n",
    "A função view em PyTorch permite alterar a forma (shape) de um tensor sem alterar seus dados subjacentes. É semelhante ao método reshape do NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1],\n",
      "        [ 2,  3],\n",
      "        [ 4,  5],\n",
      "        [ 6,  7],\n",
      "        [ 8,  9],\n",
      "        [10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# View\n",
    "tensor_reshaped = tensor.view(6, 2)\n",
    "print(tensor_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose\n",
    "A função transpose retorna um novo tensor com as dimensões transpostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  3,  6,  9],\n",
      "        [ 1,  4,  7, 10],\n",
      "        [ 2,  5,  8, 11]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "tensor_transposed = tensor.t()\n",
    "print(tensor_transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten\n",
    "A função flatten retorna um tensor 1D contendo todos os elementos do tensor original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "# Flatten\n",
    "tensor_flattened = tensor.flatten()\n",
    "print(tensor_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0],\n",
      "          [ 1],\n",
      "          [ 2],\n",
      "          [ 3],\n",
      "          [ 4],\n",
      "          [ 5]],\n",
      "\n",
      "         [[ 6],\n",
      "          [ 7],\n",
      "          [ 8],\n",
      "          [ 9],\n",
      "          [10],\n",
      "          [11]]]])\n",
      "torch.Size([1, 2, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "tensor_reshaped = tensor.reshape(1, 2, 6, 1)\n",
    "print(tensor_reshaped)\n",
    "print(tensor_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze e Unsqueeze\n",
    "- `squeeze`: Remove dimensões de tamanho 1 de um tensor.\n",
    "- `unsqueeze`: Adiciona uma dimensão de tamanho 1 em um tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze\n",
    "tensor_squeezed = tensor_reshaped.squeeze()\n",
    "print(tensor_squeezed)\n",
    "print(tensor_squeezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10, 11]]])\n",
      "torch.Size([1, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Unsqueeze\n",
    "tensor_unsqueezed = tensor_squeezed.unsqueeze(dim=0)\n",
    "print(tensor_unsqueezed)\n",
    "print(tensor_unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "O broadcasting é uma técnica que permite que tensores de diferentes formas sejam utilizados juntos em operações aritméticas. Em vez de copiar dados, o PyTorch ajusta os tensores de forma automática para que tenham formas compatíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adição de um Escalar\n",
    "\n",
    "Quando adicionamos um escalar a um tensor, o escalar é automaticamente expandido para a forma do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12, 13],\n",
      "        [14, 15, 16]])\n"
     ]
    }
   ],
   "source": [
    "# Cria um tensor 2x3\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Adiciona um escalar\n",
    "scalar = 10\n",
    "\n",
    "# Broadcasting para adicionar o escalar a cada elemento do tensor\n",
    "result = tensor + scalar\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adição de Tensores com Diferentes Dimensões\n",
    "\n",
    "Vamos adicionar um tensor 2x3 com um tensor 1x3. Neste caso, o tensor 1x3 será expandido (broadcasted) para uma forma 2x3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n"
     ]
    }
   ],
   "source": [
    "# Cria um tensor 2x3\n",
    "tensor_a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Cria um tensor 1x3\n",
    "tensor_b = torch.tensor([10, 20, 30])\n",
    "\n",
    "# Broadcasting para adicionar tensores de diferentes formas\n",
    "result = tensor_a + tensor_b\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regras de Broadcasting\n",
    "\n",
    "Para que o broadcasting funcione, os tensores devem seguir algumas regras:\n",
    "\n",
    "1. **Compatibilidade de Dimensões**: As dimensões dos tensores devem ser compatíveis. Duas dimensões são compatíveis se forem iguais ou se uma delas for 1.\n",
    "2. **Expansão Automática**: Se uma dimensão de um tensor for 1, ela será expandida para corresponder à dimensão do outro tensor.\n",
    "\n",
    "No exemplo a seguir, o tensor `tensor_c` de forma 2x1 é expandido para 2x3, e o tensor `tensor_d` de forma 1x3 é expandido para 2x3. O resultado é um tensor 2x3 onde cada elemento é o produto dos elementos correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 20, 30],\n",
      "        [20, 40, 60]])\n"
     ]
    }
   ],
   "source": [
    "# Cria um tensor 2x1\n",
    "tensor_c = torch.tensor([[1], [2]])\n",
    "\n",
    "# Cria um tensor 1x3\n",
    "tensor_d = torch.tensor([10, 20, 30])\n",
    "\n",
    "# Broadcasting para multiplicar tensores de diferentes formas\n",
    "result = tensor_c * tensor_d\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações de Redução em PyTorch\n",
    "\n",
    "As operações de redução são usadas para reduzir as dimensões de um tensor, aplicando operações como soma, média, mínimo e máximo. Essas operações são fundamentais em várias aplicações de machine learning e deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Cria um tensor 2x3\n",
    "tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(\"Tensor original:\\n\", tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soma de Todos os Elementos\n",
    "\n",
    "A função `torch.sum` calcula a soma de todos os elementos do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma de todos os elementos: 21.0\n"
     ]
    }
   ],
   "source": [
    "# Soma de todos os elementos do tensor\n",
    "sum_all = torch.sum(tensor)\n",
    "print(\"Soma de todos os elementos:\", sum_all.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soma ao Longo de um Eixo\n",
    "\n",
    "Podemos calcular a soma ao longo de um eixo específico, usando o parâmetro `dim`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma ao longo do eixo 0 (linhas): tensor([5., 7., 9.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Soma ao longo do eixo 0 (linhas)\n",
    "sum_dim0 = torch.sum(tensor, dim=0)\n",
    "print(\"Soma ao longo do eixo 0 (linhas):\", sum_dim0)\n",
    "print(sum_dim0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma ao longo do eixo 1 (colunas): tensor([ 6., 15.])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Soma ao longo do eixo 1 (colunas)\n",
    "sum_dim1 = torch.sum(tensor, dim=1)\n",
    "print(\"Soma ao longo do eixo 1 (colunas):\", sum_dim1)\n",
    "print(sum_dim1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Média dos Elementos\n",
    "\n",
    "A função `torch.mean` calcula a média dos elementos do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de todos os elementos: 3.5\n"
     ]
    }
   ],
   "source": [
    "# Média de todos os elementos do tensor\n",
    "mean_all = torch.mean(tensor)\n",
    "print(\"Média de todos os elementos:\", mean_all.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ao longo do eixo 0 (linhas): tensor([2.5000, 3.5000, 4.5000])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Média ao longo do eixo 0 (linhas)\n",
    "mean_dim0 = torch.mean(tensor, dim=0)\n",
    "print(\"Média ao longo do eixo 0 (linhas):\", mean_dim0)\n",
    "print(mean_dim0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média ao longo do eixo 1 (colunas): tensor([2., 5.])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Média ao longo do eixo 1 (colunas)\n",
    "mean_dim1 = torch.mean(tensor, dim=1)\n",
    "print(\"Média ao longo do eixo 1 (colunas):\", mean_dim1)\n",
    "print(mean_dim1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valor Mínimo e Máximo\n",
    "\n",
    "Podemos encontrar o valor mínimo e máximo de um tensor usando `torch.min` e `torch.max`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mínimo de todos os elementos: tensor(1.)\n",
      "\n",
      "Valor máximo de todos os elementos: tensor(6.)\n",
      "\n",
      "Valor mínimo ao longo do eixo 0 (linhas): tensor([1., 2., 3.])\n",
      "Índices dos valores mínimos ao longo do eixo 0 (linhas): tensor([0, 0, 0])\n",
      "\n",
      "Valor máximo ao longo do eixo 1 (colunas): tensor([3., 6.])\n",
      "Índices dos valores máximos ao longo do eixo 1 (colunas): tensor([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Valor mínimo de todos os elementos do tensor\n",
    "min_all = torch.min(tensor)\n",
    "print(\"Valor mínimo de todos os elementos:\", min_all)\n",
    "print()\n",
    "\n",
    "# Valor máximo de todos os elementos do tensor\n",
    "max_all = torch.max(tensor)\n",
    "print(\"Valor máximo de todos os elementos:\", max_all)\n",
    "print()\n",
    "\n",
    "# Valor mínimo ao longo do eixo 0 (linhas)\n",
    "min_dim0, min_indices_dim0 = torch.min(tensor, dim=0)\n",
    "print(\"Valor mínimo ao longo do eixo 0 (linhas):\", min_dim0)\n",
    "print(\"Índices dos valores mínimos ao longo do eixo 0 (linhas):\", min_indices_dim0)\n",
    "print()\n",
    "\n",
    "# Valor máximo ao longo do eixo 1 (colunas)\n",
    "max_dim1, max_indices_dim1 = torch.max(tensor, dim=1)\n",
    "print(\"Valor máximo ao longo do eixo 1 (colunas):\", max_dim1)\n",
    "print(\"Índices dos valores máximos ao longo do eixo 1 (colunas):\", max_indices_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produto dos Elementos\n",
    "\n",
    "A função `torch.prod` calcula o produto de todos os elementos do tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produto de todos os elementos: tensor(720.)\n",
      "\n",
      "Produto ao longo do eixo 0 (linhas): tensor([ 4., 10., 18.])\n",
      "\n",
      "Produto ao longo do eixo 1 (colunas): tensor([  6., 120.])\n"
     ]
    }
   ],
   "source": [
    "# Produto de todos os elementos do tensor\n",
    "prod_all = torch.prod(tensor)\n",
    "print(\"Produto de todos os elementos:\", prod_all)\n",
    "print()\n",
    "\n",
    "# Produto ao longo do eixo 0 (linhas)\n",
    "prod_dim0 = torch.prod(tensor, dim=0)\n",
    "print(\"Produto ao longo do eixo 0 (linhas):\", prod_dim0)\n",
    "print()\n",
    "\n",
    "# Produto ao longo do eixo 1 (colunas)\n",
    "prod_dim1 = torch.prod(tensor, dim=1)\n",
    "print(\"Produto ao longo do eixo 1 (colunas):\", prod_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios - PyTorch Básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1: Criação de Tensores\n",
    "\n",
    "1. Crie um tensor 1D com os valores de 1 a 10.\n",
    "2. Crie um tensor 2D de forma (3, 3) com valores aleatórios.\n",
    "3. Crie um tensor 3D de forma (2, 3, 4) com todos os valores iguais a 1.\n",
    "4. Crie um tensor de zeros com as mesmas dimensões do tensor 2D criado no exercício 2.\n",
    "5. Crie um tensor de uns com as mesmas dimensões do tensor 3D criado no exercício 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2: Manipulação de Tensores\n",
    "\n",
    "1. Dado o tensor `a = torch.tensor([[1, 2], [3, 4], [5, 6]])`, obtenha a primeira coluna.\n",
    "2. Dado o tensor `b = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])`, obtenha o subtensor `[[7, 8, 9], [10, 11, 12]]`.\n",
    "3. Dado o tensor `c = torch.tensor([1, 2, 3, 4, 5, 6])`, mude sua forma para (2, 3).\n",
    "4. Dado o tensor `d = torch.tensor([1, 2, 3, 4, 5, 6])`, adicione uma dimensão extra para que ele se torne de forma (1, 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3: Funções de Criação de Tensores\n",
    "\n",
    "1. Crie um tensor contendo valores de 0 a 1, espaçados igualmente em 5 passos.\n",
    "2. Crie um tensor contendo valores de 0 a 10, com um passo de 2.\n",
    "3. Crie um tensor de forma (3, 3) com valores aleatórios entre 0 e 10.\n",
    "4. Crie um tensor correspondente a uma imagem em escala de cinza de dimensões 128x128 com valores aleatórios entre 0 e 255.\n",
    "5. Crie um tensor correspondente a uma imagem em RGB de dimensões 128x128 com valores aleatórios entre 0 e 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4: Operações Avançadas com Tensores\n",
    "\n",
    "1. Dado o tensor `a = torch.tensor([1, 2, 3])` e `b = torch.tensor([[4], [5], [6]])`, calcule a soma de `a` e `b` usando broadcasting.\n",
    "2. Dado o tensor `a = torch.tensor([1.0, 2.0, 3.0, 4.0])`, calcule a soma de todos os elementos.\n",
    "3. Dado o tensor `a = torch.tensor([1.0, 2.0, 3.0, 4.0])`, calcule a média de todos os elementos.\n",
    "4. Dado o tensor `a = torch.tensor([1.0, 2.0, 3.0, 4.0])`, calcule a raiz quadrada de todos os elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5: Autograd e Backpropagation\n",
    "\n",
    "1. Crie um tensor `x` com os valores `[2.0, 3.0]` e `requires_grad=True`. Calcule `y = x^2` e os gradientes.\n",
    "2. Crie um tensor `x` com o valor `3.0` e `requires_grad=True`. Calcule `y = 2*x + 1` e o gradiente.\n",
    "3. Crie um tensor `x` com os valores `[1.0, 2.0, 3.0]` e `requires_grad=True`. Calcule `y = x^3` e os gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 6: Operações de Redução\n",
    "\n",
    "1. Crie um tensor de forma (4, 5) contendo valores de 1 a 20 usando `torch.arange`. Em seguida, calcule a soma de todos os elementos do tensor.\n",
    "\n",
    "2. Crie um tensor de forma (3, 4) com valores aleatórios entre 0 e 1 usando `torch.rand`. Calcule a média dos elementos ao longo do eixo 1 (colunas).\n",
    "\n",
    "3. Crie um tensor de forma (5, 5) contendo valores espaçados igualmente de 0 a 24 usando `torch.linspace`. Encontre o valor mínimo e o máximo de todos os elementos do tensor.\n",
    "\n",
    "4. Crie um tensor de forma (3, 6) com valores inteiros aleatórios entre 10 e 50 usando `torch.randint`. Calcule o produto dos elementos ao longo do eixo 0 (linhas).\n",
    "\n",
    "5. Crie um tensor de forma (2, 3, 4) com valores aleatórios entre 0 e 1 usando `torch.rand`. Encontre a soma dos elementos ao longo do eixo 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
