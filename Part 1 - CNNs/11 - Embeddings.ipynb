{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779af25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b74377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação: converte para tensor e normaliza (média e desvio de MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Dataset de treino e teste\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Subset com os primeiros 1000 para treino e 500 para validação\n",
    "train_subset = Subset(train_dataset, range(1000))\n",
    "val_subset   = Subset(test_dataset, range(500))\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_subset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96939283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(loader):\n",
    "    images, labels = next(iter(loader))\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(10):\n",
    "        img = images[i].squeeze().numpy() * 0.5 + 0.5  # desfaz a normalização\n",
    "        plt.subplot(1, 10, i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(labels[i].item())\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_batch(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),        # 28x28 → 24x24\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),           # → 12x12\n",
    "            nn.Conv2d(6, 12, 5),       # → 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),            # → 4x4\n",
    "            nn.Flatten(),                # Achata a saída para 1D\n",
    "            nn.Linear(12 * 4 * 4, 64)   # Linear layer para reduzir a dimensionalidade\n",
    "        )\n",
    "        self.classifier = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss:.4f} - Acc: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "embeddings = []\n",
    "labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        x = model.encoder(images)\n",
    "        embeddings.append(x.cpu())\n",
    "        labels_list.append(labels)\n",
    "\n",
    "X = torch.cat(embeddings).numpy()\n",
    "y = torch.cat(labels_list).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f23bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x=X_tsne[:, 0], y=X_tsne[:, 1], hue=y, palette='tab10', s=30)\n",
    "plt.title(\"t-SNE dos Embeddings da SimpleCNN\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a56a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolher duas imagens do dataset\n",
    "idx1, idx2 = 10, 13\n",
    "img1, label1 = val_subset[idx1]\n",
    "img2, label2 = val_subset[idx2]\n",
    "\n",
    "# Visualizar as imagens\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img1.squeeze() * 0.5 + 0.5, cmap='gray')\n",
    "plt.title(f\"Label: {label1}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img2.squeeze() * 0.5 + 0.5, cmap='gray')\n",
    "plt.title(f\"Label: {label2}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Extrair embeddings com encoder\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    emb1 = model.encoder(img1.unsqueeze(0).to(device)).cpu().numpy()[0]\n",
    "    emb2 = model.encoder(img2.unsqueeze(0).to(device)).cpu().numpy()[0]\n",
    "\n",
    "# Calcular distância\n",
    "dist = euclidean_distance(emb1, emb2)\n",
    "print(f\"Distância euclidiana entre os embeddings: {dist:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
